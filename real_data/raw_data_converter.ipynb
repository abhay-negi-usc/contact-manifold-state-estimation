{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (8500, 33)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.spatial.transform import Rotation\n",
    "import cicp.cicp_util as CU\n",
    "import os \n",
    "\n",
    "# geometry = \"CROSS ROUNDED\" # \"HDMI_PC\" or \"EXTRUSION\" \n",
    "geometry = \"BNC\" # \"HDMI_PC\" or \"EXTRUSION\" \n",
    "\n",
    "# base_path = f\"C:/Users/NegiA/Desktop/PIH_RSS/cicp/data/KUKA_ICP_DATA/{geometry}/map_and_obs_csv_with_fk/\"\n",
    "# base_path = f\"C:/Users/NegiA/Desktop/PIH_RSS/cicp/data/KUKA_ICP_DATA/{geometry}/map_and_obs_csvs_with_fk/\"\n",
    "\n",
    "file_type = \"MAP\" # \"MAP\" or \"OBS\" \n",
    "file_num = \"1\"  \n",
    "\n",
    "# base_path = \"C:/Users/NegiA/Desktop/PIH_RSS/cicp/data/RSS/CROSS/\"\n",
    "base_path = \"/home/rp/abhay_ws/contact-manifold-state-estimation/real_data/\"\n",
    "# all_files = os.listdir(dir)\n",
    "# all_files = [f for f in all_files if f.endswith('.npy')]\n",
    "# all_files = [f for f in all_files if \"T_B_H\" not in f] \n",
    "\n",
    "# map_files = [\n",
    "#     f\"dhanush_{geometry}_MAP1_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_MAP2_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_MAP3_moveit_fk.csv\"\n",
    "# ]\n",
    "# obs_files = [\n",
    "#     f\"dhanush_{geometry}_OBS1_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_OBS2_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_OBS3_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_OBS4_moveit_fk.csv\",\n",
    "#     f\"dhanush_{geometry}_OBS5_moveit_fk.csv\",\n",
    "# ]\n",
    "\n",
    "# all_files = [\n",
    "#     f\"dhanush_{geometry}_{file_type}{file_num}_moveit_fk.csv\",\n",
    "#     # f\"dhanush_{geometry}_{file_type}{1}_moveit_fk.csv\",\n",
    "#     # f\"dhanush_{geometry}_{file_type}{2}_moveit_fk.csv\",\n",
    "#     # f\"dhanush_{geometry}_{file_type}{3}_moveit_fk.csv\",\n",
    "#     # f\"dhanush_{geometry}_{file_type}{4}_moveit_fk.csv\",\n",
    "#     # f\"dhanush_{geometry}_{file_type}{5}_moveit_fk.csv\",\n",
    "#     # f\"Trial_{file_num}.csv\"\n",
    "# ]\n",
    "\n",
    "all_files = [\n",
    "    # \"observations_spiral_tilt_0_52328.242425766.npy\", \n",
    "    # \"observations_spiral_tilt_0_52609.254414758.npy\", \n",
    "    # \"observations_spiral_tilt_0_62624.119995464.npy\", \n",
    "    # \"observations_spiral_tilt_0_6995.55789312.npy\", \n",
    "    \"observations_spiral_tilt_0_9702.322980436.npy\", \n",
    "]\n",
    "\n",
    "all_files = [\"BNC_ideal_trajectory_forward_processed.csv\"] \n",
    "\n",
    "# saved_file_type = \".npy\" # \".csv\" or \".npy\" \n",
    "saved_file_type = \".csv\" # \".csv\" or \".npy\" \n",
    "\n",
    "# Read and combine all maps\n",
    "if saved_file_type == \".csv\":\n",
    "    map_dfs = [pd.read_csv(base_path + file) for file in all_files]\n",
    "elif saved_file_type == \".npy\":\n",
    "    map_dfs = [pd.DataFrame(np.load(base_path + file, allow_pickle=True), columns=['FK_X','FK_Y','FK_Z','FK_A','FK_B','FK_C']) for file in all_files]\n",
    "# map_dfs = [pd.read_csv(base_path + file) for file in map_files]\n",
    "# map_dfs = [pd.read_csv(base_path + file) for file in obs_files]\n",
    "combined_map_df = pd.concat(map_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# Optional: verify the shape\n",
    "print(f\"Combined shape: {combined_map_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'FK_X': 'x',\n",
    "    'FK_Y': 'y',\n",
    "    'FK_Z': 'z',\n",
    "    # 'FK_QX': 'qx',\n",
    "    # 'FK_QY': 'qy',\n",
    "    # 'FK_QZ': 'qz',\n",
    "    # 'FK_QW': 'qw',\n",
    "    'FK_A': 'a',\n",
    "    'FK_B': 'b',\n",
    "    'FK_C': 'c',\n",
    "    # 'cartForce1_X': 'FX',\n",
    "    # 'cartForce1_Y': 'FY',\n",
    "    # 'cartForce1_Z': 'FZ',\n",
    "    # 'cartTorque1_TauX': 'TX',\n",
    "    # 'cartTorque1_TauY': 'TY',\n",
    "    # 'cartTorque1_TauZ': 'TZ',\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "combined_map_df = combined_map_df[list(column_mapping.keys())].rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8500.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>718.829761</td>\n",
       "      <td>-43.221940</td>\n",
       "      <td>213.739575</td>\n",
       "      <td>148.359617</td>\n",
       "      <td>-0.858288</td>\n",
       "      <td>171.163967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.996239</td>\n",
       "      <td>0.791074</td>\n",
       "      <td>10.493942</td>\n",
       "      <td>33.028531</td>\n",
       "      <td>1.327248</td>\n",
       "      <td>45.423761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>716.917743</td>\n",
       "      <td>-45.636765</td>\n",
       "      <td>201.925594</td>\n",
       "      <td>78.386773</td>\n",
       "      <td>-3.650778</td>\n",
       "      <td>-179.996242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>718.070352</td>\n",
       "      <td>-43.598981</td>\n",
       "      <td>206.170854</td>\n",
       "      <td>164.943882</td>\n",
       "      <td>-0.665896</td>\n",
       "      <td>176.399048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>718.405366</td>\n",
       "      <td>-43.379131</td>\n",
       "      <td>206.206991</td>\n",
       "      <td>165.259084</td>\n",
       "      <td>-0.543740</td>\n",
       "      <td>176.514953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>719.813661</td>\n",
       "      <td>-43.061996</td>\n",
       "      <td>226.784955</td>\n",
       "      <td>165.902910</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>176.652182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>721.923798</td>\n",
       "      <td>-41.684743</td>\n",
       "      <td>227.269423</td>\n",
       "      <td>166.824351</td>\n",
       "      <td>0.597303</td>\n",
       "      <td>179.997379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x            y            z            a            b  \\\n",
       "count  8500.000000  8500.000000  8500.000000  8500.000000  8500.000000   \n",
       "mean    718.829761   -43.221940   213.739575   148.359617    -0.858288   \n",
       "std       0.996239     0.791074    10.493942    33.028531     1.327248   \n",
       "min     716.917743   -45.636765   201.925594    78.386773    -3.650778   \n",
       "25%     718.070352   -43.598981   206.170854   164.943882    -0.665896   \n",
       "50%     718.405366   -43.379131   206.206991   165.259084    -0.543740   \n",
       "75%     719.813661   -43.061996   226.784955   165.902910     0.153300   \n",
       "max     721.923798   -41.684743   227.269423   166.824351     0.597303   \n",
       "\n",
       "                 c  \n",
       "count  8500.000000  \n",
       "mean    171.163967  \n",
       "std      45.423761  \n",
       "min    -179.996242  \n",
       "25%     176.399048  \n",
       "50%     176.514953  \n",
       "75%     176.652182  \n",
       "max     179.997379  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_map_df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define peg and hole transformations \n",
    "\n",
    "match geometry: \n",
    "    case \"EXTRUSION\": \n",
    "        pose_insert = CU.create_pose_euler(\n",
    "            # x=691.15, y=-109.44, z=197.48, rz=-179.12, ry=1.51, rx=-179.07\n",
    "            x=691.62, y=-111.64, z=197.35, rz=+179.36, ry=0.95, rx=-179.62 # 1/4/25\n",
    "        )\n",
    "        pose_tool_wrt_flange = CU.batch_poses_xyzquat_to_poses_xyzabc(\n",
    "            CU.create_pose_quaternion(x=0, y=0, z=110.0, qx=0, qy=1, qz=0, qw=0)\n",
    "        )\n",
    "        pose_peg_wrt_flange = CU.create_pose_euler(x=0, y=0, z=85.0, rz=0, ry=180, rx=0)\n",
    "    case \"HDMI_PC\":\n",
    "        pose_insert = CU.create_pose_euler(\n",
    "            x=509.14, y=-52.68, z=441.90, rz=-139.43, ry=0.43, rx=-178.49\n",
    "        )\n",
    "        pose_tool_wrt_flange = CU.batch_poses_xyzquat_to_poses_xyzabc(\n",
    "            CU.create_pose_quaternion(x=0, y=0, z=107.0, qx=0, qy=1, qz=0, qw=0)\n",
    "        )\n",
    "        pose_peg_wrt_flange = CU.create_pose_euler(x=0, y=0, z=98.5, rz=0, ry=180, rx=0)\n",
    "    case \"CROSS\": \n",
    "        pose_insert = CU.create_pose_euler(\n",
    "            x=694.93, y=88.11, z=195.51, rz=-178.99, ry=0.56, rx=-179.52\n",
    "        )\n",
    "        pose_tool_wrt_flange = CU.batch_poses_xyzquat_to_poses_xyzabc(\n",
    "            CU.create_pose_quaternion(x=0, y=0, z=110.0, qx=0, qy=1, qz=0, qw=0)\n",
    "        )\n",
    "        pose_peg_wrt_flange = CU.create_pose_euler(x=0, y=0, z=85.0, rz=0, ry=180, rx=0)\n",
    "    case \"CROSS ROUNDED\": \n",
    "        pose_insert = CU.create_pose_euler(\n",
    "            x=692.59, y=-36.94, z=196.46, rz=179.23, ry=1.40, rx=-179.74\n",
    "        )\n",
    "        pose_tool_wrt_flange = CU.batch_poses_xyzquat_to_poses_xyzabc(\n",
    "            CU.create_pose_quaternion(x=0, y=0, z=110.0, qx=0, qy=1, qz=0, qw=0)\n",
    "        )\n",
    "        pose_peg_wrt_flange = CU.create_pose_euler(x=0, y=0, z=85.0, rz=0, ry=180, rx=0)\n",
    "    case \"BNC\": \n",
    "        pose_insert = CU.create_pose_euler(\n",
    "            x=718.089591, y=-41.785233, z=201.984210, rz=78.921215, ry=-3.352434, rx=179.542323\n",
    "        )\n",
    "        pose_tool_wrt_flange = CU.batch_poses_xyzquat_to_poses_xyzabc(\n",
    "            CU.create_pose_quaternion(x=0, y=0, z=140.0, qx=0, qy=1, qz=0, qw=0)\n",
    "        )\n",
    "        pose_peg_wrt_flange = CU.create_pose_euler(x=0, y=0, z=140.0, rz=0, ry=180, rx=0)\n",
    "\n",
    "homo_T_F_T = CU.batch_poses_xyzabc_to_matrices(pose_tool_wrt_flange)\n",
    "homo_T_F_P = CU.batch_poses_xyzabc_to_matrices(pose_peg_wrt_flange)\n",
    "\n",
    "homo_T_T_F = CU.batch_invert_homogenous_transforms(homo_T_F_T)\n",
    "homo_T_P_F = CU.batch_invert_homogenous_transforms(homo_T_F_P)\n",
    "\n",
    "homo_T_B_F0 = CU.batch_poses_xyzabc_to_matrices(pose_insert)\n",
    "homo_T_F0_B = CU.batch_invert_homogenous_transforms(homo_T_B_F0)\n",
    "\n",
    "homo_T_T0_B = CU.batch_compose_homogenous_transforms(homo_T_T_F, homo_T_F0_B)\n",
    "homo_T_P0_B = CU.batch_compose_homogenous_transforms(homo_T_P_F, homo_T_F0_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pose data at once as a single array\n",
    "poses_data = combined_map_df[[\"x\", \"y\", \"z\", \"a\", \"b\", \"c\"]].values\n",
    "\n",
    "# Convert all poses to matrices in one batch operation\n",
    "homo_T_B_Fi = CU.batch_poses_xyzabc_to_matrices(poses_data)\n",
    "\n",
    "# Perform batch transformations\n",
    "homo_T_T0_Ti = CU.batch_compose_homogenous_transforms(\n",
    "    CU.batch_compose_homogenous_transforms(\n",
    "        np.repeat(homo_T_T0_B, homo_T_B_Fi.shape[0], axis=0), homo_T_B_Fi\n",
    "    ),\n",
    "    np.repeat(homo_T_F_T, homo_T_B_Fi.shape[0], axis=0),\n",
    ")\n",
    "\n",
    "homo_T_P0_Pi = CU.batch_compose_homogenous_transforms(\n",
    "    CU.batch_compose_homogenous_transforms(\n",
    "        np.repeat(homo_T_P0_B, homo_T_B_Fi.shape[0], axis=0), homo_T_B_Fi\n",
    "    ),\n",
    "    np.repeat(homo_T_F_P, homo_T_B_Fi.shape[0], axis=0),\n",
    "    # np.repeat(np.eye(4).reshape(1,4,4), homo_T_B_Fi.shape[0], axis=0), # FIXME: this is a quick fix when data is T_B_P\n",
    ")\n",
    "\n",
    "# Convert matrices back to poses in one batch\n",
    "result_poses_tool = CU.batch_matrices_to_poses_xyzabc(homo_T_T0_Ti)\n",
    "result_poses_peg = CU.batch_matrices_to_poses_xyzabc(homo_T_P0_Pi)\n",
    "\n",
    "# Create result dataframe with transformed poses\n",
    "df_tool = pd.DataFrame(result_poses_tool, columns=[\"x\", \"y\", \"z\", \"a\", \"b\", \"c\"]) \n",
    "df_peg = pd.DataFrame(result_poses_peg, columns=[\"x\", \"y\", \"z\", \"a\", \"b\", \"c\"]) # NOTE: use this df (peg wrt hole) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform wrench data from base frame to peg frame\n",
    "# # NOTE: this only rotates the wrench data but does not factor torque due to force on moment arm \n",
    "# df_peg[['FX','FY','FZ','TX','TY','TZ']] = np.zeros((len(df_peg),6))\n",
    "# for index, row in df_peg.iterrows():\n",
    "#     cart_force = combined_map_df.loc[index,['FX','FY','FZ']].values \n",
    "#     cart_torque = combined_map_df.loc[index,['TX','TY','TZ']].values  \n",
    "#     r = Rotation.from_euler('xyz', row[['c','b','a']].values, degrees=True) \n",
    "#     peg_force = r.apply(cart_force)\n",
    "#     peg_torque = r.apply(cart_torque)\n",
    "#     df_peg.loc[index, 'FX'] = peg_force[0]\n",
    "#     df_peg.loc[index, 'FY'] = peg_force[1]\n",
    "#     df_peg.loc[index, 'FZ'] = peg_force[2]\n",
    "#     df_peg.loc[index, 'TX'] = peg_torque[0]\n",
    "#     df_peg.loc[index, 'TY'] = peg_torque[1]\n",
    "#     df_peg.loc[index, 'TZ'] = peg_torque[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use log map to compute rotation vector \n",
    "def rotation_matrix_to_log_vector(R):\n",
    "    \"\"\"Convert a rotation matrix to a rotation vector using the logarithm map.\"\"\"\n",
    "    theta = np.arccos((np.trace(R) - 1) / 2)\n",
    "    if theta < 1e-6:\n",
    "        return np.zeros(3)\n",
    "    else:\n",
    "        ln_R = (theta / (2 * np.sin(theta))) * (R - R.T)\n",
    "        return np.array([ln_R[2, 1], ln_R[0, 2], ln_R[1, 0]])\n",
    "    \n",
    "df_peg[['wx','wy','wz']] = np.zeros((len(df_peg),3))\n",
    "for index, row in df_peg.iterrows():\n",
    "    r = Rotation.from_euler('xyz', row[['c','b','a']].values, degrees=True) \n",
    "    R = r.as_matrix()\n",
    "    log_vec = rotation_matrix_to_log_vector(R)\n",
    "    df_peg.loc[index, 'wx'] = log_vec[0]\n",
    "    df_peg.loc[index, 'wy'] = log_vec[1]\n",
    "    df_peg.loc[index, 'wz'] = log_vec[2]\n",
    "    \n",
    "df_peg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv and pkl files \n",
    "# df_peg.to_csv(base_path+\"hdmi_real_map.csv\", index=False) \n",
    "# df_peg.to_pickle(base_path+\"hdmi_real_map.pkl\") \n",
    "# df_peg.to_csv(base_path+\"extrusion_real_obs_5.csv\", index=False) \n",
    "# df_peg.to_pickle(base_path+\"extrusion_real_obs_5.pkl\") \n",
    "\n",
    "# df_peg.to_csv(base_path+f\"{geometry}_real_{file_type}_{file_num}_with_wrench.csv\", index=False)\n",
    "# df_peg.to_csv(base_path+f\"{geometry}_real_{file_type}_{file_num}.csv\", index=False)  \n",
    "df_peg.to_csv(base_path+f\"{geometry}_ideal_trajectory_forward_pose_H_P.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (887534964.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    error to stop here\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "error to stop here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CU.plot_map(df_peg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(dataframe: pd.DataFrame):\n",
    "    # Create a figure with 2x3 subplots (better layout for 6 dimensions)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Histograms of Poses', fontsize=16)\n",
    "\n",
    "    # Flatten axes for easier iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Create histograms for each dimension\n",
    "    for idx, col in enumerate([\"x\", \"y\", \"z\", \"a\", \"b\", \"c\"]):\n",
    "        axes[idx].hist(dataframe[col], bins=50, edgecolor='black')\n",
    "        axes[idx].set_title(f'{col} Distribution')\n",
    "        axes[idx].set_xlabel(f'{col} value')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        \n",
    "        # Add mean and std as text\n",
    "        mean = dataframe[col].mean()\n",
    "        std = dataframe[col].std()\n",
    "        axes[idx].text(0.05, 0.95, f'Mean: {mean:.3f}\\nStd: {std:.3f}', \n",
    "                    transform=axes[idx].transAxes,\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(df_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(df_peg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering using corners (not needed for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data by extrema points\n",
    "peg_length = 25.0 \n",
    "peg_width = 25.0 \n",
    "half_peg_width = peg_width/2  \n",
    "extrema_points_coords_peg_frame = [\n",
    "    np.array([+half_peg_width, +half_peg_width, -peg_length]),\n",
    "    np.array([-half_peg_width, +half_peg_width, -peg_length]),\n",
    "    np.array([-half_peg_width, -half_peg_width, -peg_length]),\n",
    "    np.array([+half_peg_width, -half_peg_width, -peg_length]),\n",
    "] \n",
    "\n",
    "idx_below_top_surface = [] \n",
    "z_top_surface_thresh = 0.1  \n",
    "for index, row in df_combined.iterrows(): \n",
    "    T_H_P = pose_to_T(row[['X','Y','Z','A','B','C']].values) \n",
    "    for i, extrema_point in enumerate(extrema_points_coords_peg_frame): \n",
    "        extrema_points_coords_hole_frame = T_H_P @ np.vstack((extrema_point.reshape(3,1), np.array([[1]]))) # T_HE = T_HP * T_PE \n",
    "        z_extrema_point = extrema_points_coords_hole_frame[2,0]\n",
    "        if z_extrema_point < z_top_surface_thresh: \n",
    "            idx_below_top_surface.append(index) \n",
    "            break  \n",
    "\n",
    "print(len(idx_below_top_surface)) \n",
    "print(len(df_combined)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data and output \n",
    "df_combined_filtered = df_combined.iloc[idx_below_top_surface,:] \n",
    "df_combined_filtered.reset_index(drop=True, inplace=True) \n",
    "# save filtered data to csv \n",
    "file_path = f\"/home/aero/abhay_ws/contact_maps/{geometry}_real_obs.csv\" \n",
    "df_combined_filtered.to_csv(file_path) \n",
    "\n",
    "# save df as pkl file \n",
    "file_path = f\"/home/aero/abhay_ws/contact_maps/{geometry}_real_obs_df.pkl\" \n",
    "df_combined_filtered.to_pickle(file_path) \n",
    "\n",
    "# save np array as pkl file\n",
    "file_path = f\"/home/aero/abhay_ws/contact_maps/{geometry}_real_obs_np.pkl\" \n",
    "np.save(file_path, df_combined_filtered.to_numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_filtered.max() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
